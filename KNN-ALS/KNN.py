# -*- coding: utf-8 -*-
"""KNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hPS3q0nTV2gXIWhQh2XpQ2uWlVEDZjXM
"""

'''
Need to install the surprise library first using:
!pip install scikit-surprise
'''

import pandas as pd
import numpy as np
from surprise import SVD,KNNBaseline,Reader,Dataset,KNNBasic
from surprise.model_selection import cross_validate,train_test_split
import heapq
from collections import defaultdict
from operator import itemgetter
from sklearn.model_selection import train_test_split

data = pd.read_csv('steam_users_purchase_play.csv')

# Drop rows with missing values
data = data.dropna()
data = data.loc[data.hours != 0]

data

# Remove game with less than 30 users
game_freq = pd.DataFrame(data.groupby('game_name').size(),columns=['count'])
game_freq.head()
threshold_play_freq = 30
popular_game_name = list(set(game_freq.query('count>=@threshold_play_freq').index))
data_popular_game = data[data.game_name.isin(popular_game_name)]

# Remove users with less than 10 games
user_cnt = pd.DataFrame(data.groupby('user_id').size(),columns=['count'])
user_cnt.head()
threshold_val = 10
active_user = list(set(user_cnt.query('count>=@threshold_val').index))

#upadte data_popular_game
data_popular_game_with_active_user = data_popular_game[data_popular_game.user_id.isin(active_user)]

# Convert implicit rating(playtime) into explicit ratings from 1-5 according the length of playtime
data = data_popular_game_with_active_user.sort_values(['user_id','hours'])
data['rating'] = data.groupby('user_id')['hours'].apply(lambda x: pd.cut(x, bins=5, labels=[1,2,3,4,5]))

data

data = data.drop(['hours','purchase','play'],axis=1)

# Participating data into train and test set
data_train, data_test = train_test_split(data, test_size = 0.2,random_state=42)

reader = Reader(line_format="user item rating")
dataset = Dataset.load_from_df(data_train,reader=reader)
trainset = dataset.build_full_trainset()

pd.DataFrame(list(trainset.all_ratings()))
max(pd.DataFrame(list(trainset.all_ratings()))[1])

trainset.to_inner_iid('Unturned')  #item name -> item id
trainset.to_raw_uid(0)  #user id -> user

# Item based KNN
item_based_sim_option = {'name': 'cosine', 'user_based': False}
algo = KNNBasic(sim_option = item_based_sim_option)
cross_validate(algo,dataset,cv=3,verbose=True)

# Compute similarity matrix
similarity_matrix = KNNBasic(sim_options={
        'name': 'cosine',
        'user_based': False
        })\
        .fit(trainset)\
        .compute_similarities()

# fuction for recommandation
def recommand_KNN(raw_id, k, trainset, similarity_matrix, N):
  '''
  raw_id: the original user_id
  k: number of neighbor
  trainset: training data
  similarity_matrix: the similarity_matrix calculated by KNN algo
  N: number of games we want to recommand
  '''
  test_subject = raw_id
  test_subject_iid = trainset.to_inner_uid(test_subject)
  # Get the top K items user rated
  test_subject_ratings = trainset.ur[test_subject_iid]
  k_neighbors = heapq.nlargest(k, test_subject_ratings, key=lambda t: t[1])
  candidates = defaultdict(float)

  for itemID, rating in k_neighbors:
      try:
        similaritities = similarity_matrix[itemID]
        for innerID, score in enumerate(similaritities):
            candidates[innerID] += score * (rating / 5.0)
      except:
        continue
  
  # Build a dictionary of movies the user has watched
  watched = {}
  for itemID, rating in trainset.ur[test_subject_iid]:
    watched[itemID] = 1

  # Add items to list of user's recommendations
  # If they are similar to their favorite movies, and have not already been watched.
  recommendations = []

  position = 0
  for itemID, rating_sum in sorted(candidates.items(), key=itemgetter(1), reverse=True):
    if not itemID in watched:
      recommendations.append(trainset.to_raw_iid(itemID))
      position += 1
      if (position > N): break # We only want top N
  return recommendations

recommendations = recommand_KNN(76767	, 10, trainset, similarity_matrix, 10)
for rec in recommendations:
  print("Game: ", rec)

df_recommendations = pd.DataFrame({'game': recommendations})
df_recommendations

# Calculate precision
user_list = set(data_train.user_id)&set(data_test.user_id)
precision = 0

for uid in user_list:
    game_reco = recommand_KNN(uid, 50, trainset, similarity_matrix, 5)
    data_test_user = data_test[data_test.user_id == uid].game_name.tolist()
    games = []
    precision_i = 0
    cnt = 0
    for i in range(0,len(game_reco)):
        if game_reco[i] in data_test_user:
          cnt += 1
    precision_i = cnt/min(len(data_test_user),len(game_reco))
    precision += precision_i

avg_precision = precision/(len(user_list))

# Calculate recall
recall = 0

for uid in user_list:
    game_reco = recommand_KNN(uid, 50, trainset, similarity_matrix, 5)
    data_test_user = data_test[data_test.user_id == uid].game_name.tolist()
    games = []
    recall_i = 0
    TP = 0
    FN = 0
    for i in range(0,len(game_reco)):
        if game_reco[i] in data_test_user:
          TP += 1
    for j in range(0,len(data_test_user)):
        if data_test_user[j] not in game_reco:
          FN += 1
    recall_i = TP/(TP+FN)
    recall += recall_i

avg_recall = recall/(len(user_list))

F1_score = 2*avg_precision*avg_recall/(avg_precision+avg_recall)

print('Precision: ', avg_precision)
print('Recall: ', avg_recall)
print('F1_score: ', F1_score)